{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Only read up to 4096 bytes, > 4096 has 100% malware rate\n",
    "MAX_SIZE = 4096\n",
    "# # MAX_SIZE = 98304\n",
    "TOTAL_ROWS = 113636\n",
    "USE_COLS = list(range(2, MAX_SIZE))\n",
    "ROWS = 10000\n",
    "\n",
    "train = pd.read_csv(\"./data/train/train.zip\", nrows=ROWS, usecols=USE_COLS, header=None, names = list(range(0, MAX_SIZE)))\n",
    "train = train.fillna(0, downcast='infer')\n",
    "\n",
    "train_label = pd.read_csv(\"./data/train_label.csv\", usecols=[1], nrows=ROWS)\n",
    "train_label = np.reshape(train_label, (ROWS, ))\n",
    "\n",
    "x_train = train.values\n",
    "y_train = train_label.values\n",
    "y_train = np.reshape(y_train, (ROWS, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras import Sequential\n",
    "\n",
    "# CHANGE THIS FILEPATH\n",
    "filepath = 'mlp_model.h5'\n",
    "mlp_model = keras.models.load_model(filepath)\n",
    "ypred_mlp = mlp_model.predict(x_train)\n",
    "\n",
    "ypred_mlp = np.reshape(ypred_mlp, (ROWS, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# HERE USE THE LIGHTGBM WITH PARSER\n",
    "bst_model = lgb.Booster(model_file='./model-99034.txt')\n",
    "ypred_gbm = bst_model.predict(x_train, num_iteration=bst.best_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "157\n",
      "Epoch 1/50157\n",
      "\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 0.1216 - acc: 0.9633\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0932 - acc: 0.9870\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0708 - acc: 0.9897\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0529 - acc: 0.9914\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0385 - acc: 0.9922\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0294 - acc: 0.9928\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0262 - acc: 0.9928\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0278 - acc: 0.9925\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0290 - acc: 0.9925\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0280 - acc: 0.9927\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0280 - acc: 0.9925\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0277 - acc: 0.9926\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0287 - acc: 0.9926\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0287 - acc: 0.9927\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0283 - acc: 0.9926\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0288 - acc: 0.9925\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0289 - acc: 0.9925\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0282 - acc: 0.9924\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0281 - acc: 0.9924\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0284 - acc: 0.9926\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0294 - acc: 0.9926\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0302 - acc: 0.9926\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0300 - acc: 0.9925\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0299 - acc: 0.9926\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0309 - acc: 0.9925\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0308 - acc: 0.9926\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0307 - acc: 0.9926\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0307 - acc: 0.9926\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0307 - acc: 0.9927\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0306 - acc: 0.9927\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0307 - acc: 0.9927\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0307 - acc: 0.9928\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0307 - acc: 0.9927\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0307 - acc: 0.9927\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0307 - acc: 0.9927\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0307 - acc: 0.9928\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0307 - acc: 0.9926\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0307 - acc: 0.9926\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0306 - acc: 0.9925\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0316 - acc: 0.9925\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0326 - acc: 0.9926\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0319 - acc: 0.9928\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0309 - acc: 0.9926\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0316 - acc: 0.9925\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0316 - acc: 0.9925\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0315 - acc: 0.9925\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0315 - acc: 0.9927\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0315 - acc: 0.9926\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0315 - acc: 0.9926\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0315 - acc: 0.9927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5541b1afd0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import Sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "class MyGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, x1_set, x2_set, y_set, batch_size):\n",
    "        self.x1, self.x2, self.y = x1_set, x2_set, y_set,\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        print(str(int(np.ceil(len(self.x1) / float(self.batch_size)))))\n",
    "        return int(np.ceil(len(self.x1) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x1 = self.x1[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x2 = self.x2[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = np.zeros((len(batch_x1), 2))\n",
    "        \n",
    "        for i in range(len(batch_x1)):\n",
    "            batch_x[i, :] = [batch_x1[i], batch_x2[i]]\n",
    "        \n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "    \n",
    "    \n",
    "seq = MyGenerator(ypred_gbm, ypred_mlp, y_train, batch_size)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=2, kernel_initializer=keras.initializers.Constant(value=1/2)))\n",
    "\n",
    "adam=optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=adam,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(y_train.shape)\n",
    "model.fit_generator(generator=seq, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TOTAL_ROWS = 133223\n",
    "TEST_ROWS = TEST_TOTAL_ROWS\n",
    "test = pd.read_csv(\"./data/actual_test.csv\", nrows=TEST_ROWS, usecols=USE_COLS, header=None, names = list(range(0, MAX_SIZE)))\n",
    "x_test = test.values\n",
    "x_test = np.nan_to_num(x_test)\n",
    "\n",
    "ytest_mlp = mlp_model.predict(x_test)\n",
    "ytest_mlp = np.reshape(ytest_mlp, (TEST_ROWS, ))\n",
    "\n",
    "ytest_gbm = bst_model.predict(x_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    \n",
    "total = weights[0][0][0] + weights[0][1][0]\n",
    "gbm_weight = weights[0][0][0] / total\n",
    "mlp_weight = weights[0][1][0] / total\n",
    "\n",
    "\n",
    "ytest_res = ytest_mlp*mlp_weight + ytest_gbm*gbm_weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
