{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "%matplotlib inline\n",
    "\n",
    "# Size the plot appropriately for online display\n",
    "plt.rcParams['figure.figsize'] = (12.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct import unpack\n",
    "\n",
    "# https://marcin-chwedczuk.github.io/a-closer-look-at-portable-executable-msdos-stub\n",
    "MS_DOS_HEADER_FORMAT = '<2b13h8bhh20bl'\n",
    "# Assembly code to print out the stub\n",
    "MS_DOS_STUB_FORMAT = '<{:d}b'\n",
    "# Signature\n",
    "SIGNATURE_FORMAT = '4s'\n",
    "# COFF File Header\n",
    "# [0] & [-1]: multi-class\n",
    "COFF_FILE_HEADER_FORMAT = '<hhiiihh'\n",
    "# image optional header\n",
    "# [0] - 2 classes\n",
    "# [23] & [24] - multi-class\n",
    "IMAGE_OPTIONAL_HEADER_STANDARD_FORMAT = '<hbb5i'\n",
    "MAX_LEN = 4096\n",
    "\n",
    "def parse_hex(string):\n",
    "    max_size = len(string)\n",
    "    if max_size < 64:\n",
    "        raise Exception('max_size error', max_size)\n",
    "    \n",
    "    ms_dos_header = unpack(MS_DOS_HEADER_FORMAT, string[:64])\n",
    "    pe_sig_start = ms_dos_header[-1]\n",
    "    pe_sig_end = pe_sig_start + 4\n",
    "\n",
    "    ms_dos_stub = ()\n",
    "    if pe_sig_start > 64:\n",
    "        ms_dos_stub = unpack(MS_DOS_STUB_FORMAT.format(pe_sig_start - 64),\n",
    "                             string[64:pe_sig_start])\n",
    "    \n",
    "    sig = unpack(SIGNATURE_FORMAT, string[pe_sig_start:pe_sig_end])\n",
    "    \n",
    "    coff_start = pe_sig_end\n",
    "    coff_end = pe_sig_end + 20\n",
    "    coff = unpack(COFF_FILE_HEADER_FORMAT,\n",
    "                 string[pe_sig_end:coff_end])\n",
    "    \n",
    "    optional_header_size = coff[-2]\n",
    "    img_opt_hdr_start = coff_end\n",
    "    img_opt_hdr_mid = coff_end + 24\n",
    "    img_opt_hrd_end = coff_end + optional_header_size\n",
    "    \n",
    "    optional_header = ()\n",
    "    if optional_header_size != 0 and max_size > img_opt_hrd_end:\n",
    "        optional_header = unpack(IMAGE_OPTIONAL_HEADER_STANDARD_FORMAT,\n",
    "                                 string[img_opt_hdr_start:img_opt_hdr_mid])\n",
    "        pe_format = optional_header[0]\n",
    "        \n",
    "        # Optional Header Windows-Specific Fields (Image Only)\n",
    "        if pe_format == 267:\n",
    "            # format is PE32\n",
    "            optional_header += unpack('<iiii6h4ihh4iii16q',\n",
    "                                 string[img_opt_hdr_mid:img_opt_hrd_end])\n",
    "\n",
    "        elif pe_format == 523:\n",
    "            # format is PE32+\n",
    "            optional_header += (np.nan, )\n",
    "            optional_header += unpack('<qii6h4ihh4qii16q',\n",
    "                                     string[img_opt_hdr_mid:img_opt_hrd_end])\n",
    "        else:\n",
    "            raise Exception('pe_format error', pe_format)\n",
    "    else:\n",
    "        raise Exception('coff error', coff)\n",
    "    \n",
    "#     number_of_sections = coff[1]\n",
    "#     section_start = img_opt_hrd_end\n",
    "#     section_end = img_opt_hrd_end + 40\n",
    "#     sections = []\n",
    "#     if max_size > section_end:\n",
    "#         for sec in range(number_of_sections):\n",
    "#             sections += [unpack('8s6ihhi', string[section_start:section_end])]\n",
    "#             section_start = section_end\n",
    "#             section_end += 40\n",
    "\n",
    "#     section_data = [max_size, max_size > MAX_LEN] + list(string[section_end:MAX_LEN])\n",
    "\n",
    "#     return ms_dos_header, ms_dos_stub, sig, coff, optional_header, sections, section_data\n",
    "\n",
    "section_map = {}\n",
    "def normalize_pe(parsed):\n",
    "    global section_map\n",
    "    max_headers = 26\n",
    "    N = 4400\n",
    "    ms_dos_header, ms_dos_stub, sig, coff, optional_header, sections, section_data = parsed\n",
    "    \n",
    "    output_sections = []\n",
    "    for s in sections[:max_headers]:\n",
    "        key = s[0]\n",
    "        if not key in section_map:\n",
    "            section_map[key] = len(section_map)\n",
    "        output_sections += [section_map[key]] + list(s[1:])\n",
    "    for i in range(len(sections), max_headers):\n",
    "        # pad with null\n",
    "        output_sections += [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "    output_sections += [len(sections) > max_headers,]\n",
    "    \n",
    "    ms_dos_hash = [0 for i in range(0,256)]\n",
    "    for x in ms_dos_stub:\n",
    "        ms_dos_hash[x] += 1\n",
    "\n",
    "    output = list(ms_dos_header) + ms_dos_hash + list(coff) + list(optional_header) + output_sections + section_data\n",
    "    output += [0] * (N - len(output))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4365\n",
      "Failed to parse: is_malware = 0\n",
      "('coff error', (332, 5, 1332508402, 0, 0, 224, 271))\n",
      "63958\n",
      "Failed to parse: is_malware = 0\n",
      "('coff error', (332, 4, 1161596910, 0, 0, 224, 259))\n",
      "65735\n",
      "Failed to parse: is_malware = 1\n",
      "('coff error', (332, 3, 1491985532, 0, 0, 224, 258))\n",
      "69772\n",
      "Failed to parse: is_malware = 0\n",
      "('coff error', (332, 5, 1161590502, 0, 0, 224, 259))\n",
      "71446\n",
      "Failed to parse: is_malware = 0\n",
      "('max_size error', 36)\n",
      "73497\n",
      "Failed to parse: is_malware = 0\n",
      "('unpack requires a buffer of 200 bytes',)\n",
      "77095\n",
      "Failed to parse: is_malware = 0\n",
      "('unpack requires a buffer of 216 bytes',)\n",
      "107337\n",
      "Failed to parse: is_malware = 0\n",
      "('unpack requires a buffer of 200 bytes',)\n",
      "(0, 0)\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "train_label = []\n",
    "\n",
    "combined = \"./data/train_combined.csv\"\n",
    "with open(combined) as combinedcsvfile:\n",
    "    combinedreader = csv.reader(combinedcsvfile)\n",
    "    for i, row in enumerate(combinedreader):\n",
    "        try:\n",
    "            parsed = parse_hex(bytes([int(x) for x in row[:-1]]))\n",
    "        except Exception as inst:\n",
    "            print(i)\n",
    "            print(\"Failed to parse: is_malware =\", row[-1])\n",
    "            print(inst.args)\n",
    "            continue\n",
    "#         out = normalize_pe(parsed)\n",
    "#         train += [out]\n",
    "#         train_label += [row[-1]]\n",
    "\n",
    "train = pd.DataFrame(train)\n",
    "train_label = np.array(train_label)\n",
    "print(train.shape)\n",
    "print(train_label.shape)\n",
    "train.to_csv('./data/parsed_train.csv', index=False, header=False)\n",
    "pd.DataFrame(train_label).to_csv('./data/parsed_labels.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse\n",
      "('unpack requires a buffer of 200 bytes',)\n",
      "Failed to parse\n",
      "('unpack requires a buffer of 200 bytes',)\n",
      "Failed to parse\n",
      "('unpack requires a buffer of 200 bytes',)\n",
      "Failed to parse\n",
      "('unpack requires a buffer of 200 bytes',)\n",
      "Failed to parse\n",
      "('unpack requires a buffer of 200 bytes',)\n",
      "Failed to parse\n",
      "('unpack requires a buffer of 200 bytes',)\n",
      "Failed to parse\n",
      "('unpack requires a buffer of 200 bytes',)\n",
      "Failed to parse\n",
      "('unpack requires a buffer of 200 bytes',)\n",
      "Failed to parse\n",
      "('coff error', (332, 5, 1468633261, 0, 0, 224, 8450))\n",
      "Failed to parse\n",
      "('unpack requires a buffer of 200 bytes',)\n",
      "Failed to parse\n",
      "('unpack requires a buffer of 200 bytes',)\n",
      "Failed to parse\n",
      "('unpack requires a buffer of 200 bytes',)\n",
      "Failed to parse\n",
      "('unpack requires a buffer of 200 bytes',)\n",
      "Failed to parse\n",
      "('unpack requires a buffer of 200 bytes',)\n",
      "Failed to parse\n",
      "('unpack requires a buffer of 200 bytes',)\n",
      "Failed to parse\n",
      "('unpack requires a buffer of 200 bytes',)\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "indexes = []\n",
    "with open('./data/test.csv') as combinedcsvfile:\n",
    "    combinedreader = csv.reader(combinedcsvfile)\n",
    "    for i, row in enumerate(combinedreader):\n",
    "        try:\n",
    "            parsed = parse_hex(bytes([int(x) for x in row]))\n",
    "            out = normalize_pe(parsed)\n",
    "            test += [out]\n",
    "            indexes += [1]\n",
    "        except Exception as inst:\n",
    "            print(\"Failed to parse\")\n",
    "            print(inst.args)\n",
    "            indexes += [0]\n",
    "\n",
    "pd.DataFrame(indexes).to_csv('./data/parsed_indicies.csv', index=False, header=False)\n",
    "pd.DataFrame(test).to_csv('./data/parsed_test.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_ROWS = 113636\n",
    "ROWS = TOTAL_ROWS\n",
    "\n",
    "train = pd.read_csv(\"./parsed_train.csv\", nrows=ROWS, header=None)\n",
    "train_label = pd.read_csv(\"./parsed_labels.csv\", nrows=ROWS, header=None)\n",
    "\n",
    "assert train.shape[0] == train_label.shape[0], \"Train and label shapes are different\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4390</th>\n",
       "      <th>4391</th>\n",
       "      <th>4392</th>\n",
       "      <th>4393</th>\n",
       "      <th>4394</th>\n",
       "      <th>4395</th>\n",
       "      <th>4396</th>\n",
       "      <th>4397</th>\n",
       "      <th>4398</th>\n",
       "      <th>4399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77</td>\n",
       "      <td>90</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>90</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>90</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>90</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77</td>\n",
       "      <td>90</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>77</td>\n",
       "      <td>90</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>77</td>\n",
       "      <td>90</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>77</td>\n",
       "      <td>90</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>77</td>\n",
       "      <td>90</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>77</td>\n",
       "      <td>90</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 4400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...   4390  \\\n",
       "0    77    90   144     3     0     4     0    -1     0   184  ...      0   \n",
       "1    77    90   144     3     0     4     0    -1     0   184  ...      0   \n",
       "2    77    90   144     3     0     4     0    -1     0   184  ...      0   \n",
       "3    77    90   144     3     0     4     0    -1     0   184  ...      0   \n",
       "4    77    90   144     3     0     4     0    -1     0   184  ...      0   \n",
       "5    77    90   144     3     0     4     0    -1     0   184  ...      0   \n",
       "6    77    90   144     3     0     4     0    -1     0   184  ...      0   \n",
       "7    77    90    64     1     0     2     0    -1     0   184  ...      0   \n",
       "8    77    90   144     3     0     4     0    -1     0   184  ...      0   \n",
       "9    77    90   144     3     0     4     0    -1     0   184  ...      0   \n",
       "\n",
       "   4391  4392  4393  4394  4395  4396  4397  4398  4399  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0  \n",
       "5     0     0     0     0     0     0     0     0     0  \n",
       "6     0     0     0     0     0     0     0     0     0  \n",
       "7     0     0     0     0     0     0     0     0     0  \n",
       "8     0     0     0     0     0     0     0     0     0  \n",
       "9     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[10 rows x 4400 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.random.rand(len(train)) < 0.8\n",
    "\n",
    "x_train = train[mask]\n",
    "y_train = train_label[mask]\n",
    "x_test = train[~mask]\n",
    "y_test = train_label[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import gc\n",
    "train_data = lgb.Dataset(x_train, label=y_train.values.ravel())\n",
    "\n",
    "# Create validation data\n",
    "test_data = train_data.create_valid(x_test, label=y_test.values.ravel())\n",
    "\n",
    "train = None\n",
    "x_train = None\n",
    "y_train = None\n",
    "x_test = None\n",
    "y_test = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:104: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.676802\n",
      "Training until validation scores don't improve for 35 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.661077\n",
      "[3]\tvalid_0's binary_logloss: 0.645974\n",
      "[4]\tvalid_0's binary_logloss: 0.631424\n",
      "[5]\tvalid_0's binary_logloss: 0.617421\n",
      "[6]\tvalid_0's binary_logloss: 0.603937\n",
      "[7]\tvalid_0's binary_logloss: 0.590911\n",
      "[8]\tvalid_0's binary_logloss: 0.595605\n",
      "[9]\tvalid_0's binary_logloss: 0.582892\n",
      "[10]\tvalid_0's binary_logloss: 0.57058\n",
      "[11]\tvalid_0's binary_logloss: 0.558654\n",
      "[12]\tvalid_0's binary_logloss: 0.562845\n",
      "[13]\tvalid_0's binary_logloss: 0.551224\n",
      "[14]\tvalid_0's binary_logloss: 0.540003\n",
      "[15]\tvalid_0's binary_logloss: 0.529082\n",
      "[16]\tvalid_0's binary_logloss: 0.518481\n",
      "[17]\tvalid_0's binary_logloss: 0.508239\n",
      "[18]\tvalid_0's binary_logloss: 0.498264\n",
      "[19]\tvalid_0's binary_logloss: 0.488651\n",
      "[20]\tvalid_0's binary_logloss: 0.47929\n",
      "[21]\tvalid_0's binary_logloss: 0.481687\n",
      "[22]\tvalid_0's binary_logloss: 0.472622\n",
      "[23]\tvalid_0's binary_logloss: 0.463752\n",
      "[24]\tvalid_0's binary_logloss: 0.455135\n",
      "[25]\tvalid_0's binary_logloss: 0.446833\n",
      "[26]\tvalid_0's binary_logloss: 0.438831\n",
      "[27]\tvalid_0's binary_logloss: 0.430993\n",
      "[28]\tvalid_0's binary_logloss: 0.43389\n",
      "[29]\tvalid_0's binary_logloss: 0.426223\n",
      "[30]\tvalid_0's binary_logloss: 0.418741\n",
      "[31]\tvalid_0's binary_logloss: 0.41925\n",
      "[32]\tvalid_0's binary_logloss: 0.411833\n",
      "[33]\tvalid_0's binary_logloss: 0.404636\n",
      "[34]\tvalid_0's binary_logloss: 0.397658\n",
      "[35]\tvalid_0's binary_logloss: 0.401129\n",
      "[36]\tvalid_0's binary_logloss: 0.406328\n",
      "[37]\tvalid_0's binary_logloss: 0.399319\n",
      "[38]\tvalid_0's binary_logloss: 0.392524\n",
      "[39]\tvalid_0's binary_logloss: 0.385936\n",
      "[40]\tvalid_0's binary_logloss: 0.384008\n",
      "[41]\tvalid_0's binary_logloss: 0.387767\n",
      "[42]\tvalid_0's binary_logloss: 0.3813\n",
      "[43]\tvalid_0's binary_logloss: 0.384805\n",
      "[44]\tvalid_0's binary_logloss: 0.37825\n",
      "[45]\tvalid_0's binary_logloss: 0.371996\n",
      "[46]\tvalid_0's binary_logloss: 0.377236\n",
      "[47]\tvalid_0's binary_logloss: 0.371071\n",
      "[48]\tvalid_0's binary_logloss: 0.370416\n",
      "[49]\tvalid_0's binary_logloss: 0.374302\n",
      "[50]\tvalid_0's binary_logloss: 0.37846\n",
      "[51]\tvalid_0's binary_logloss: 0.372313\n",
      "[52]\tvalid_0's binary_logloss: 0.366101\n",
      "[53]\tvalid_0's binary_logloss: 0.369007\n",
      "[54]\tvalid_0's binary_logloss: 0.363065\n",
      "[55]\tvalid_0's binary_logloss: 0.35715\n",
      "[56]\tvalid_0's binary_logloss: 0.36143\n",
      "[57]\tvalid_0's binary_logloss: 0.355556\n",
      "[58]\tvalid_0's binary_logloss: 0.35961\n",
      "[59]\tvalid_0's binary_logloss: 0.363519\n",
      "[60]\tvalid_0's binary_logloss: 0.357712\n",
      "[61]\tvalid_0's binary_logloss: 0.360707\n",
      "[62]\tvalid_0's binary_logloss: 0.35492\n",
      "[63]\tvalid_0's binary_logloss: 0.349359\n",
      "[64]\tvalid_0's binary_logloss: 0.352463\n",
      "[65]\tvalid_0's binary_logloss: 0.355653\n",
      "[66]\tvalid_0's binary_logloss: 0.349986\n",
      "[67]\tvalid_0's binary_logloss: 0.344512\n",
      "[68]\tvalid_0's binary_logloss: 0.339061\n",
      "[69]\tvalid_0's binary_logloss: 0.342317\n",
      "[70]\tvalid_0's binary_logloss: 0.344101\n",
      "[71]\tvalid_0's binary_logloss: 0.346304\n",
      "[72]\tvalid_0's binary_logloss: 0.340919\n",
      "[73]\tvalid_0's binary_logloss: 0.335488\n",
      "[74]\tvalid_0's binary_logloss: 0.338053\n",
      "[75]\tvalid_0's binary_logloss: 0.332829\n",
      "[76]\tvalid_0's binary_logloss: 0.333211\n",
      "[77]\tvalid_0's binary_logloss: 0.335417\n",
      "[78]\tvalid_0's binary_logloss: 0.337645\n",
      "[79]\tvalid_0's binary_logloss: 0.332495\n",
      "[80]\tvalid_0's binary_logloss: 0.327318\n",
      "[81]\tvalid_0's binary_logloss: 0.329771\n",
      "[82]\tvalid_0's binary_logloss: 0.324842\n",
      "[83]\tvalid_0's binary_logloss: 0.3277\n",
      "[84]\tvalid_0's binary_logloss: 0.330682\n",
      "[85]\tvalid_0's binary_logloss: 0.333458\n",
      "[86]\tvalid_0's binary_logloss: 0.328424\n",
      "[87]\tvalid_0's binary_logloss: 0.323402\n",
      "[88]\tvalid_0's binary_logloss: 0.326721\n",
      "[89]\tvalid_0's binary_logloss: 0.328729\n",
      "[90]\tvalid_0's binary_logloss: 0.331601\n",
      "[91]\tvalid_0's binary_logloss: 0.334212\n",
      "[92]\tvalid_0's binary_logloss: 0.329118\n",
      "[93]\tvalid_0's binary_logloss: 0.324166\n",
      "[94]\tvalid_0's binary_logloss: 0.326897\n",
      "[95]\tvalid_0's binary_logloss: 0.329052\n",
      "[96]\tvalid_0's binary_logloss: 0.331279\n",
      "[97]\tvalid_0's binary_logloss: 0.32631\n",
      "[98]\tvalid_0's binary_logloss: 0.328623\n",
      "[99]\tvalid_0's binary_logloss: 0.323679\n",
      "[100]\tvalid_0's binary_logloss: 0.318739\n",
      "[101]\tvalid_0's binary_logloss: 0.321754\n",
      "[102]\tvalid_0's binary_logloss: 0.32417\n",
      "[103]\tvalid_0's binary_logloss: 0.326725\n",
      "[104]\tvalid_0's binary_logloss: 0.321804\n",
      "[105]\tvalid_0's binary_logloss: 0.324501\n",
      "[106]\tvalid_0's binary_logloss: 0.327149\n",
      "[107]\tvalid_0's binary_logloss: 0.329752\n",
      "[108]\tvalid_0's binary_logloss: 0.324826\n",
      "[109]\tvalid_0's binary_logloss: 0.32696\n",
      "[110]\tvalid_0's binary_logloss: 0.329421\n",
      "[111]\tvalid_0's binary_logloss: 0.324504\n",
      "[112]\tvalid_0's binary_logloss: 0.319696\n",
      "[113]\tvalid_0's binary_logloss: 0.31484\n",
      "[114]\tvalid_0's binary_logloss: 0.310097\n",
      "[115]\tvalid_0's binary_logloss: 0.305514\n",
      "[116]\tvalid_0's binary_logloss: 0.301077\n",
      "[117]\tvalid_0's binary_logloss: 0.302898\n",
      "[118]\tvalid_0's binary_logloss: 0.298614\n",
      "[119]\tvalid_0's binary_logloss: 0.300598\n",
      "[120]\tvalid_0's binary_logloss: 0.302934\n",
      "[121]\tvalid_0's binary_logloss: 0.305283\n",
      "[122]\tvalid_0's binary_logloss: 0.307666\n",
      "[123]\tvalid_0's binary_logloss: 0.303271\n",
      "[124]\tvalid_0's binary_logloss: 0.298875\n",
      "[125]\tvalid_0's binary_logloss: 0.30079\n",
      "[126]\tvalid_0's binary_logloss: 0.303049\n",
      "[127]\tvalid_0's binary_logloss: 0.298709\n",
      "[128]\tvalid_0's binary_logloss: 0.300665\n",
      "[129]\tvalid_0's binary_logloss: 0.296443\n",
      "[130]\tvalid_0's binary_logloss: 0.29219\n",
      "[131]\tvalid_0's binary_logloss: 0.293993\n",
      "[132]\tvalid_0's binary_logloss: 0.289931\n",
      "[133]\tvalid_0's binary_logloss: 0.285845\n",
      "[134]\tvalid_0's binary_logloss: 0.288011\n",
      "[135]\tvalid_0's binary_logloss: 0.284008\n",
      "[136]\tvalid_0's binary_logloss: 0.286479\n",
      "[137]\tvalid_0's binary_logloss: 0.288431\n",
      "[138]\tvalid_0's binary_logloss: 0.284387\n",
      "[139]\tvalid_0's binary_logloss: 0.280495\n",
      "[140]\tvalid_0's binary_logloss: 0.282861\n",
      "[141]\tvalid_0's binary_logloss: 0.284798\n",
      "[142]\tvalid_0's binary_logloss: 0.286798\n",
      "[143]\tvalid_0's binary_logloss: 0.28291\n",
      "[144]\tvalid_0's binary_logloss: 0.284676\n",
      "[145]\tvalid_0's binary_logloss: 0.280723\n",
      "[146]\tvalid_0's binary_logloss: 0.28308\n",
      "[147]\tvalid_0's binary_logloss: 0.28528\n",
      "[148]\tvalid_0's binary_logloss: 0.287414\n",
      "[149]\tvalid_0's binary_logloss: 0.28345\n",
      "[150]\tvalid_0's binary_logloss: 0.279632\n",
      "[151]\tvalid_0's binary_logloss: 0.281903\n",
      "[152]\tvalid_0's binary_logloss: 0.284002\n",
      "[153]\tvalid_0's binary_logloss: 0.280113\n",
      "[154]\tvalid_0's binary_logloss: 0.281797\n",
      "[155]\tvalid_0's binary_logloss: 0.277912\n",
      "[156]\tvalid_0's binary_logloss: 0.280118\n",
      "[157]\tvalid_0's binary_logloss: 0.281283\n",
      "[158]\tvalid_0's binary_logloss: 0.283487\n",
      "[159]\tvalid_0's binary_logloss: 0.285692\n",
      "[160]\tvalid_0's binary_logloss: 0.287887\n",
      "[161]\tvalid_0's binary_logloss: 0.283897\n",
      "[162]\tvalid_0's binary_logloss: 0.285392\n",
      "[163]\tvalid_0's binary_logloss: 0.281482\n",
      "[164]\tvalid_0's binary_logloss: 0.277615\n",
      "[165]\tvalid_0's binary_logloss: 0.273809\n",
      "[166]\tvalid_0's binary_logloss: 0.270139\n",
      "[167]\tvalid_0's binary_logloss: 0.266546\n",
      "[168]\tvalid_0's binary_logloss: 0.26302\n",
      "[169]\tvalid_0's binary_logloss: 0.259609\n",
      "[170]\tvalid_0's binary_logloss: 0.261503\n",
      "[171]\tvalid_0's binary_logloss: 0.258099\n",
      "[172]\tvalid_0's binary_logloss: 0.25987\n",
      "[173]\tvalid_0's binary_logloss: 0.256522\n",
      "[174]\tvalid_0's binary_logloss: 0.253221\n",
      "[175]\tvalid_0's binary_logloss: 0.249978\n",
      "[176]\tvalid_0's binary_logloss: 0.251427\n",
      "[177]\tvalid_0's binary_logloss: 0.25317\n",
      "[178]\tvalid_0's binary_logloss: 0.254823\n",
      "[179]\tvalid_0's binary_logloss: 0.251549\n",
      "[180]\tvalid_0's binary_logloss: 0.253163\n",
      "[181]\tvalid_0's binary_logloss: 0.249983\n",
      "[182]\tvalid_0's binary_logloss: 0.246801\n",
      "[183]\tvalid_0's binary_logloss: 0.24366\n",
      "[184]\tvalid_0's binary_logloss: 0.240631\n",
      "[185]\tvalid_0's binary_logloss: 0.24271\n",
      "[186]\tvalid_0's binary_logloss: 0.239644\n",
      "[187]\tvalid_0's binary_logloss: 0.236677\n",
      "[188]\tvalid_0's binary_logloss: 0.233754\n",
      "[189]\tvalid_0's binary_logloss: 0.235528\n",
      "[190]\tvalid_0's binary_logloss: 0.237205\n",
      "[191]\tvalid_0's binary_logloss: 0.234354\n",
      "[192]\tvalid_0's binary_logloss: 0.231503\n",
      "[193]\tvalid_0's binary_logloss: 0.228738\n",
      "[194]\tvalid_0's binary_logloss: 0.230281\n",
      "[195]\tvalid_0's binary_logloss: 0.231705\n",
      "[196]\tvalid_0's binary_logloss: 0.228942\n",
      "[197]\tvalid_0's binary_logloss: 0.230186\n",
      "[198]\tvalid_0's binary_logloss: 0.231722\n",
      "[199]\tvalid_0's binary_logloss: 0.228961\n",
      "[200]\tvalid_0's binary_logloss: 0.230672\n",
      "[201]\tvalid_0's binary_logloss: 0.232315\n",
      "[202]\tvalid_0's binary_logloss: 0.233925\n",
      "[203]\tvalid_0's binary_logloss: 0.231102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[204]\tvalid_0's binary_logloss: 0.232464\n",
      "[205]\tvalid_0's binary_logloss: 0.234006\n",
      "[206]\tvalid_0's binary_logloss: 0.231186\n",
      "[207]\tvalid_0's binary_logloss: 0.232674\n",
      "[208]\tvalid_0's binary_logloss: 0.229928\n",
      "[209]\tvalid_0's binary_logloss: 0.231594\n",
      "[210]\tvalid_0's binary_logloss: 0.233039\n",
      "[211]\tvalid_0's binary_logloss: 0.234496\n",
      "[212]\tvalid_0's binary_logloss: 0.231621\n",
      "[213]\tvalid_0's binary_logloss: 0.22884\n",
      "[214]\tvalid_0's binary_logloss: 0.226138\n",
      "[215]\tvalid_0's binary_logloss: 0.223508\n",
      "[216]\tvalid_0's binary_logloss: 0.225094\n",
      "[217]\tvalid_0's binary_logloss: 0.222534\n",
      "[218]\tvalid_0's binary_logloss: 0.219973\n",
      "[219]\tvalid_0's binary_logloss: 0.221319\n",
      "[220]\tvalid_0's binary_logloss: 0.218788\n",
      "[221]\tvalid_0's binary_logloss: 0.220252\n",
      "[222]\tvalid_0's binary_logloss: 0.217686\n",
      "[223]\tvalid_0's binary_logloss: 0.21517\n",
      "[224]\tvalid_0's binary_logloss: 0.216709\n",
      "[225]\tvalid_0's binary_logloss: 0.218378\n",
      "[226]\tvalid_0's binary_logloss: 0.219728\n",
      "[227]\tvalid_0's binary_logloss: 0.220772\n",
      "[228]\tvalid_0's binary_logloss: 0.218278\n",
      "[229]\tvalid_0's binary_logloss: 0.219621\n",
      "[230]\tvalid_0's binary_logloss: 0.217134\n",
      "[231]\tvalid_0's binary_logloss: 0.214665\n",
      "[232]\tvalid_0's binary_logloss: 0.212259\n",
      "[233]\tvalid_0's binary_logloss: 0.213522\n",
      "[234]\tvalid_0's binary_logloss: 0.21109\n",
      "[235]\tvalid_0's binary_logloss: 0.212359\n",
      "[236]\tvalid_0's binary_logloss: 0.210018\n",
      "[237]\tvalid_0's binary_logloss: 0.20768\n",
      "[238]\tvalid_0's binary_logloss: 0.205368\n",
      "[239]\tvalid_0's binary_logloss: 0.20314\n",
      "[240]\tvalid_0's binary_logloss: 0.200916\n",
      "[241]\tvalid_0's binary_logloss: 0.202322\n",
      "[242]\tvalid_0's binary_logloss: 0.200141\n",
      "[243]\tvalid_0's binary_logloss: 0.201567\n",
      "[244]\tvalid_0's binary_logloss: 0.202817\n",
      "[245]\tvalid_0's binary_logloss: 0.200707\n",
      "[246]\tvalid_0's binary_logloss: 0.198606\n",
      "[247]\tvalid_0's binary_logloss: 0.19652\n",
      "[248]\tvalid_0's binary_logloss: 0.197889\n",
      "[249]\tvalid_0's binary_logloss: 0.199038\n",
      "[250]\tvalid_0's binary_logloss: 0.196954\n",
      "[251]\tvalid_0's binary_logloss: 0.19822\n",
      "[252]\tvalid_0's binary_logloss: 0.199403\n",
      "[253]\tvalid_0's binary_logloss: 0.197327\n",
      "[254]\tvalid_0's binary_logloss: 0.195274\n",
      "[255]\tvalid_0's binary_logloss: 0.193237\n",
      "[256]\tvalid_0's binary_logloss: 0.191266\n",
      "[257]\tvalid_0's binary_logloss: 0.189321\n",
      "[258]\tvalid_0's binary_logloss: 0.187411\n",
      "[259]\tvalid_0's binary_logloss: 0.188562\n",
      "[260]\tvalid_0's binary_logloss: 0.189845\n",
      "[261]\tvalid_0's binary_logloss: 0.191012\n",
      "[262]\tvalid_0's binary_logloss: 0.189095\n",
      "[263]\tvalid_0's binary_logloss: 0.18722\n",
      "[264]\tvalid_0's binary_logloss: 0.18537\n",
      "[265]\tvalid_0's binary_logloss: 0.183535\n",
      "[266]\tvalid_0's binary_logloss: 0.181765\n",
      "[267]\tvalid_0's binary_logloss: 0.182869\n",
      "[268]\tvalid_0's binary_logloss: 0.181132\n",
      "[269]\tvalid_0's binary_logloss: 0.182267\n",
      "[270]\tvalid_0's binary_logloss: 0.180527\n",
      "[271]\tvalid_0's binary_logloss: 0.181636\n",
      "[272]\tvalid_0's binary_logloss: 0.1799\n",
      "[273]\tvalid_0's binary_logloss: 0.178159\n",
      "[274]\tvalid_0's binary_logloss: 0.179178\n",
      "[275]\tvalid_0's binary_logloss: 0.177458\n",
      "[276]\tvalid_0's binary_logloss: 0.178631\n",
      "[277]\tvalid_0's binary_logloss: 0.176948\n",
      "[278]\tvalid_0's binary_logloss: 0.177926\n",
      "[279]\tvalid_0's binary_logloss: 0.176302\n",
      "[280]\tvalid_0's binary_logloss: 0.177358\n",
      "[281]\tvalid_0's binary_logloss: 0.178303\n",
      "[282]\tvalid_0's binary_logloss: 0.17664\n",
      "[283]\tvalid_0's binary_logloss: 0.177704\n",
      "[284]\tvalid_0's binary_logloss: 0.176043\n",
      "[285]\tvalid_0's binary_logloss: 0.174388\n",
      "[286]\tvalid_0's binary_logloss: 0.17276\n",
      "[287]\tvalid_0's binary_logloss: 0.171168\n",
      "[288]\tvalid_0's binary_logloss: 0.172152\n",
      "[289]\tvalid_0's binary_logloss: 0.17056\n",
      "[290]\tvalid_0's binary_logloss: 0.169013\n",
      "[291]\tvalid_0's binary_logloss: 0.167524\n",
      "[292]\tvalid_0's binary_logloss: 0.168565\n",
      "[293]\tvalid_0's binary_logloss: 0.169576\n",
      "[294]\tvalid_0's binary_logloss: 0.168071\n",
      "[295]\tvalid_0's binary_logloss: 0.169115\n",
      "[296]\tvalid_0's binary_logloss: 0.170105\n",
      "[297]\tvalid_0's binary_logloss: 0.168558\n",
      "[298]\tvalid_0's binary_logloss: 0.169472\n",
      "[299]\tvalid_0's binary_logloss: 0.167932\n",
      "[300]\tvalid_0's binary_logloss: 0.168788\n",
      "[301]\tvalid_0's binary_logloss: 0.16979\n",
      "[302]\tvalid_0's binary_logloss: 0.16829\n",
      "[303]\tvalid_0's binary_logloss: 0.169238\n",
      "[304]\tvalid_0's binary_logloss: 0.170199\n",
      "[305]\tvalid_0's binary_logloss: 0.171228\n",
      "[306]\tvalid_0's binary_logloss: 0.172134\n",
      "[307]\tvalid_0's binary_logloss: 0.172949\n",
      "[308]\tvalid_0's binary_logloss: 0.17138\n",
      "[309]\tvalid_0's binary_logloss: 0.17227\n",
      "[310]\tvalid_0's binary_logloss: 0.170724\n",
      "[311]\tvalid_0's binary_logloss: 0.169192\n",
      "[312]\tvalid_0's binary_logloss: 0.167678\n",
      "[313]\tvalid_0's binary_logloss: 0.166143\n",
      "[314]\tvalid_0's binary_logloss: 0.166948\n",
      "[315]\tvalid_0's binary_logloss: 0.167879\n",
      "[316]\tvalid_0's binary_logloss: 0.166389\n",
      "[317]\tvalid_0's binary_logloss: 0.164884\n",
      "[318]\tvalid_0's binary_logloss: 0.163467\n",
      "[319]\tvalid_0's binary_logloss: 0.164294\n",
      "[320]\tvalid_0's binary_logloss: 0.162884\n",
      "[321]\tvalid_0's binary_logloss: 0.163629\n",
      "[322]\tvalid_0's binary_logloss: 0.162176\n",
      "[323]\tvalid_0's binary_logloss: 0.160809\n",
      "[324]\tvalid_0's binary_logloss: 0.161705\n",
      "[325]\tvalid_0's binary_logloss: 0.160347\n",
      "[326]\tvalid_0's binary_logloss: 0.161236\n",
      "[327]\tvalid_0's binary_logloss: 0.159791\n",
      "[328]\tvalid_0's binary_logloss: 0.160584\n",
      "[329]\tvalid_0's binary_logloss: 0.159179\n",
      "[330]\tvalid_0's binary_logloss: 0.160022\n",
      "[331]\tvalid_0's binary_logloss: 0.160865\n",
      "[332]\tvalid_0's binary_logloss: 0.161663\n",
      "[333]\tvalid_0's binary_logloss: 0.162542\n",
      "[334]\tvalid_0's binary_logloss: 0.16344\n",
      "[335]\tvalid_0's binary_logloss: 0.162015\n",
      "[336]\tvalid_0's binary_logloss: 0.162878\n",
      "[337]\tvalid_0's binary_logloss: 0.161451\n",
      "[338]\tvalid_0's binary_logloss: 0.160054\n",
      "[339]\tvalid_0's binary_logloss: 0.160805\n",
      "[340]\tvalid_0's binary_logloss: 0.161655\n",
      "[341]\tvalid_0's binary_logloss: 0.160238\n",
      "[342]\tvalid_0's binary_logloss: 0.158861\n",
      "[343]\tvalid_0's binary_logloss: 0.157564\n",
      "[344]\tvalid_0's binary_logloss: 0.158335\n",
      "[345]\tvalid_0's binary_logloss: 0.157049\n",
      "[346]\tvalid_0's binary_logloss: 0.155765\n",
      "[347]\tvalid_0's binary_logloss: 0.15652\n",
      "[348]\tvalid_0's binary_logloss: 0.155123\n",
      "[349]\tvalid_0's binary_logloss: 0.153796\n",
      "[350]\tvalid_0's binary_logloss: 0.154639\n",
      "[351]\tvalid_0's binary_logloss: 0.15333\n",
      "[352]\tvalid_0's binary_logloss: 0.152056\n",
      "[353]\tvalid_0's binary_logloss: 0.150808\n",
      "[354]\tvalid_0's binary_logloss: 0.151472\n",
      "[355]\tvalid_0's binary_logloss: 0.152245\n",
      "[356]\tvalid_0's binary_logloss: 0.151031\n",
      "[357]\tvalid_0's binary_logloss: 0.151716\n",
      "[358]\tvalid_0's binary_logloss: 0.150461\n",
      "[359]\tvalid_0's binary_logloss: 0.151222\n",
      "[360]\tvalid_0's binary_logloss: 0.149989\n",
      "[361]\tvalid_0's binary_logloss: 0.148799\n",
      "[362]\tvalid_0's binary_logloss: 0.147629\n",
      "[363]\tvalid_0's binary_logloss: 0.148359\n",
      "[364]\tvalid_0's binary_logloss: 0.149041\n",
      "[365]\tvalid_0's binary_logloss: 0.147831\n",
      "[366]\tvalid_0's binary_logloss: 0.148532\n",
      "[367]\tvalid_0's binary_logloss: 0.149319\n",
      "[368]\tvalid_0's binary_logloss: 0.148113\n",
      "[369]\tvalid_0's binary_logloss: 0.14874\n",
      "[370]\tvalid_0's binary_logloss: 0.147576\n",
      "[371]\tvalid_0's binary_logloss: 0.14829\n",
      "[372]\tvalid_0's binary_logloss: 0.147121\n",
      "[373]\tvalid_0's binary_logloss: 0.145889\n",
      "[374]\tvalid_0's binary_logloss: 0.144742\n",
      "[375]\tvalid_0's binary_logloss: 0.143589\n",
      "[376]\tvalid_0's binary_logloss: 0.144226\n",
      "[377]\tvalid_0's binary_logloss: 0.143111\n",
      "[378]\tvalid_0's binary_logloss: 0.143824\n",
      "[379]\tvalid_0's binary_logloss: 0.144502\n",
      "[380]\tvalid_0's binary_logloss: 0.143388\n",
      "[381]\tvalid_0's binary_logloss: 0.144086\n",
      "[382]\tvalid_0's binary_logloss: 0.144794\n",
      "[383]\tvalid_0's binary_logloss: 0.1437\n",
      "[384]\tvalid_0's binary_logloss: 0.142603\n",
      "[385]\tvalid_0's binary_logloss: 0.143321\n",
      "[386]\tvalid_0's binary_logloss: 0.142232\n",
      "[387]\tvalid_0's binary_logloss: 0.141167\n",
      "[388]\tvalid_0's binary_logloss: 0.140086\n",
      "[389]\tvalid_0's binary_logloss: 0.139023\n",
      "[390]\tvalid_0's binary_logloss: 0.137981\n",
      "[391]\tvalid_0's binary_logloss: 0.138629\n",
      "[392]\tvalid_0's binary_logloss: 0.137628\n",
      "[393]\tvalid_0's binary_logloss: 0.136642\n",
      "[394]\tvalid_0's binary_logloss: 0.135673\n",
      "[395]\tvalid_0's binary_logloss: 0.134725\n",
      "[396]\tvalid_0's binary_logloss: 0.13531\n",
      "[397]\tvalid_0's binary_logloss: 0.134393\n",
      "[398]\tvalid_0's binary_logloss: 0.133449\n",
      "[399]\tvalid_0's binary_logloss: 0.132521\n",
      "[400]\tvalid_0's binary_logloss: 0.131623\n",
      "[401]\tvalid_0's binary_logloss: 0.132147\n",
      "[402]\tvalid_0's binary_logloss: 0.131269\n",
      "[403]\tvalid_0's binary_logloss: 0.131785\n",
      "[404]\tvalid_0's binary_logloss: 0.130917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[405]\tvalid_0's binary_logloss: 0.130041\n",
      "[406]\tvalid_0's binary_logloss: 0.130575\n",
      "[407]\tvalid_0's binary_logloss: 0.129691\n",
      "[408]\tvalid_0's binary_logloss: 0.130278\n",
      "[409]\tvalid_0's binary_logloss: 0.12945\n",
      "[410]\tvalid_0's binary_logloss: 0.128609\n",
      "[411]\tvalid_0's binary_logloss: 0.127772\n",
      "[412]\tvalid_0's binary_logloss: 0.128298\n",
      "[413]\tvalid_0's binary_logloss: 0.128857\n",
      "[414]\tvalid_0's binary_logloss: 0.128025\n",
      "[415]\tvalid_0's binary_logloss: 0.127212\n",
      "[416]\tvalid_0's binary_logloss: 0.126413\n",
      "[417]\tvalid_0's binary_logloss: 0.126985\n",
      "[418]\tvalid_0's binary_logloss: 0.127541\n",
      "[419]\tvalid_0's binary_logloss: 0.126749\n",
      "[420]\tvalid_0's binary_logloss: 0.127281\n",
      "[421]\tvalid_0's binary_logloss: 0.126507\n",
      "[422]\tvalid_0's binary_logloss: 0.12573\n",
      "[423]\tvalid_0's binary_logloss: 0.124924\n",
      "[424]\tvalid_0's binary_logloss: 0.124165\n",
      "[425]\tvalid_0's binary_logloss: 0.12469\n",
      "[426]\tvalid_0's binary_logloss: 0.123887\n",
      "[427]\tvalid_0's binary_logloss: 0.123115\n",
      "[428]\tvalid_0's binary_logloss: 0.123645\n",
      "[429]\tvalid_0's binary_logloss: 0.122909\n",
      "[430]\tvalid_0's binary_logloss: 0.12337\n",
      "[431]\tvalid_0's binary_logloss: 0.122626\n",
      "[432]\tvalid_0's binary_logloss: 0.121874\n",
      "[433]\tvalid_0's binary_logloss: 0.121112\n",
      "[434]\tvalid_0's binary_logloss: 0.121595\n",
      "[435]\tvalid_0's binary_logloss: 0.122055\n",
      "[436]\tvalid_0's binary_logloss: 0.121361\n",
      "[437]\tvalid_0's binary_logloss: 0.120626\n",
      "[438]\tvalid_0's binary_logloss: 0.121056\n",
      "[439]\tvalid_0's binary_logloss: 0.121508\n",
      "[440]\tvalid_0's binary_logloss: 0.120818\n",
      "[441]\tvalid_0's binary_logloss: 0.120093\n",
      "[442]\tvalid_0's binary_logloss: 0.119385\n",
      "[443]\tvalid_0's binary_logloss: 0.119821\n",
      "[444]\tvalid_0's binary_logloss: 0.119104\n",
      "[445]\tvalid_0's binary_logloss: 0.118451\n",
      "[446]\tvalid_0's binary_logloss: 0.118891\n",
      "[447]\tvalid_0's binary_logloss: 0.118212\n",
      "[448]\tvalid_0's binary_logloss: 0.117567\n",
      "[449]\tvalid_0's binary_logloss: 0.116905\n",
      "[450]\tvalid_0's binary_logloss: 0.116291\n",
      "[451]\tvalid_0's binary_logloss: 0.115644\n",
      "[452]\tvalid_0's binary_logloss: 0.116062\n",
      "[453]\tvalid_0's binary_logloss: 0.116482\n",
      "[454]\tvalid_0's binary_logloss: 0.116894\n",
      "[455]\tvalid_0's binary_logloss: 0.11629\n",
      "[456]\tvalid_0's binary_logloss: 0.116723\n",
      "[457]\tvalid_0's binary_logloss: 0.117181\n",
      "[458]\tvalid_0's binary_logloss: 0.116517\n",
      "[459]\tvalid_0's binary_logloss: 0.115891\n",
      "[460]\tvalid_0's binary_logloss: 0.116277\n",
      "[461]\tvalid_0's binary_logloss: 0.115647\n",
      "[462]\tvalid_0's binary_logloss: 0.116073\n",
      "[463]\tvalid_0's binary_logloss: 0.116499\n",
      "[464]\tvalid_0's binary_logloss: 0.115855\n",
      "[465]\tvalid_0's binary_logloss: 0.115263\n",
      "[466]\tvalid_0's binary_logloss: 0.115676\n",
      "[467]\tvalid_0's binary_logloss: 0.115049\n",
      "[468]\tvalid_0's binary_logloss: 0.115434\n",
      "[469]\tvalid_0's binary_logloss: 0.114796\n",
      "[470]\tvalid_0's binary_logloss: 0.115209\n",
      "[471]\tvalid_0's binary_logloss: 0.11463\n",
      "[472]\tvalid_0's binary_logloss: 0.115008\n",
      "[473]\tvalid_0's binary_logloss: 0.114389\n",
      "[474]\tvalid_0's binary_logloss: 0.113815\n",
      "[475]\tvalid_0's binary_logloss: 0.113247\n",
      "[476]\tvalid_0's binary_logloss: 0.113593\n",
      "[477]\tvalid_0's binary_logloss: 0.113007\n",
      "[478]\tvalid_0's binary_logloss: 0.113416\n",
      "[479]\tvalid_0's binary_logloss: 0.113816\n",
      "[480]\tvalid_0's binary_logloss: 0.113246\n",
      "[481]\tvalid_0's binary_logloss: 0.112635\n",
      "[482]\tvalid_0's binary_logloss: 0.112068\n",
      "[483]\tvalid_0's binary_logloss: 0.111534\n",
      "[484]\tvalid_0's binary_logloss: 0.110911\n",
      "[485]\tvalid_0's binary_logloss: 0.11126\n",
      "[486]\tvalid_0's binary_logloss: 0.110737\n",
      "[487]\tvalid_0's binary_logloss: 0.110221\n",
      "[488]\tvalid_0's binary_logloss: 0.109635\n",
      "[489]\tvalid_0's binary_logloss: 0.109138\n",
      "[490]\tvalid_0's binary_logloss: 0.109495\n",
      "[491]\tvalid_0's binary_logloss: 0.10984\n",
      "[492]\tvalid_0's binary_logloss: 0.110175\n",
      "[493]\tvalid_0's binary_logloss: 0.11053\n",
      "[494]\tvalid_0's binary_logloss: 0.110001\n",
      "[495]\tvalid_0's binary_logloss: 0.109417\n",
      "[496]\tvalid_0's binary_logloss: 0.108932\n",
      "[497]\tvalid_0's binary_logloss: 0.108351\n",
      "[498]\tvalid_0's binary_logloss: 0.107887\n",
      "[499]\tvalid_0's binary_logloss: 0.1082\n",
      "[500]\tvalid_0's binary_logloss: 0.107723\n",
      "[501]\tvalid_0's binary_logloss: 0.108061\n",
      "[502]\tvalid_0's binary_logloss: 0.107504\n",
      "[503]\tvalid_0's binary_logloss: 0.107046\n",
      "[504]\tvalid_0's binary_logloss: 0.107376\n",
      "[505]\tvalid_0's binary_logloss: 0.107671\n",
      "[506]\tvalid_0's binary_logloss: 0.107207\n",
      "[507]\tvalid_0's binary_logloss: 0.106686\n",
      "[508]\tvalid_0's binary_logloss: 0.106202\n",
      "[509]\tvalid_0's binary_logloss: 0.105741\n",
      "[510]\tvalid_0's binary_logloss: 0.105268\n",
      "[511]\tvalid_0's binary_logloss: 0.105594\n",
      "[512]\tvalid_0's binary_logloss: 0.10517\n",
      "[513]\tvalid_0's binary_logloss: 0.104716\n",
      "[514]\tvalid_0's binary_logloss: 0.1042\n",
      "[515]\tvalid_0's binary_logloss: 0.103784\n",
      "[516]\tvalid_0's binary_logloss: 0.104071\n",
      "[517]\tvalid_0's binary_logloss: 0.104366\n",
      "[518]\tvalid_0's binary_logloss: 0.104619\n",
      "[519]\tvalid_0's binary_logloss: 0.104933\n",
      "[520]\tvalid_0's binary_logloss: 0.104453\n",
      "[521]\tvalid_0's binary_logloss: 0.104029\n",
      "[522]\tvalid_0's binary_logloss: 0.10433\n",
      "[523]\tvalid_0's binary_logloss: 0.10464\n",
      "[524]\tvalid_0's binary_logloss: 0.104947\n",
      "[525]\tvalid_0's binary_logloss: 0.105238\n",
      "[526]\tvalid_0's binary_logloss: 0.104793\n",
      "[527]\tvalid_0's binary_logloss: 0.105083\n",
      "[528]\tvalid_0's binary_logloss: 0.104505\n",
      "[529]\tvalid_0's binary_logloss: 0.104051\n",
      "[530]\tvalid_0's binary_logloss: 0.103607\n",
      "[531]\tvalid_0's binary_logloss: 0.103893\n",
      "[532]\tvalid_0's binary_logloss: 0.103493\n",
      "[533]\tvalid_0's binary_logloss: 0.103774\n",
      "[534]\tvalid_0's binary_logloss: 0.103348\n",
      "[535]\tvalid_0's binary_logloss: 0.102893\n",
      "[536]\tvalid_0's binary_logloss: 0.103136\n",
      "[537]\tvalid_0's binary_logloss: 0.102697\n",
      "[538]\tvalid_0's binary_logloss: 0.102165\n",
      "[539]\tvalid_0's binary_logloss: 0.102464\n",
      "[540]\tvalid_0's binary_logloss: 0.10276\n",
      "[541]\tvalid_0's binary_logloss: 0.103049\n",
      "[542]\tvalid_0's binary_logloss: 0.102619\n",
      "[543]\tvalid_0's binary_logloss: 0.10292\n",
      "[544]\tvalid_0's binary_logloss: 0.103207\n",
      "[545]\tvalid_0's binary_logloss: 0.102789\n",
      "[546]\tvalid_0's binary_logloss: 0.102283\n",
      "[547]\tvalid_0's binary_logloss: 0.101861\n",
      "[548]\tvalid_0's binary_logloss: 0.101341\n",
      "[549]\tvalid_0's binary_logloss: 0.101606\n",
      "[550]\tvalid_0's binary_logloss: 0.101143\n",
      "[551]\tvalid_0's binary_logloss: 0.100742\n",
      "[552]\tvalid_0's binary_logloss: 0.10029\n",
      "[553]\tvalid_0's binary_logloss: 0.100601\n",
      "[554]\tvalid_0's binary_logloss: 0.100843\n",
      "[555]\tvalid_0's binary_logloss: 0.100431\n",
      "[556]\tvalid_0's binary_logloss: 0.100702\n",
      "[557]\tvalid_0's binary_logloss: 0.10097\n",
      "[558]\tvalid_0's binary_logloss: 0.100604\n",
      "[559]\tvalid_0's binary_logloss: 0.100164\n",
      "[560]\tvalid_0's binary_logloss: 0.099773\n",
      "[561]\tvalid_0's binary_logloss: 0.100037\n",
      "[562]\tvalid_0's binary_logloss: 0.100288\n",
      "[563]\tvalid_0's binary_logloss: 0.100531\n",
      "[564]\tvalid_0's binary_logloss: 0.10082\n",
      "[565]\tvalid_0's binary_logloss: 0.100306\n",
      "[566]\tvalid_0's binary_logloss: 0.0999291\n",
      "[567]\tvalid_0's binary_logloss: 0.0994544\n",
      "[568]\tvalid_0's binary_logloss: 0.0996836\n",
      "[569]\tvalid_0's binary_logloss: 0.0999526\n",
      "[570]\tvalid_0's binary_logloss: 0.100193\n",
      "[571]\tvalid_0's binary_logloss: 0.0997852\n",
      "[572]\tvalid_0's binary_logloss: 0.0994197\n",
      "[573]\tvalid_0's binary_logloss: 0.0996445\n",
      "[574]\tvalid_0's binary_logloss: 0.0999075\n",
      "[575]\tvalid_0's binary_logloss: 0.0994308\n",
      "[576]\tvalid_0's binary_logloss: 0.0997092\n",
      "[577]\tvalid_0's binary_logloss: 0.0999503\n",
      "[578]\tvalid_0's binary_logloss: 0.100216\n",
      "[579]\tvalid_0's binary_logloss: 0.100455\n",
      "[580]\tvalid_0's binary_logloss: 0.100714\n",
      "[581]\tvalid_0's binary_logloss: 0.100315\n",
      "[582]\tvalid_0's binary_logloss: 0.100557\n",
      "[583]\tvalid_0's binary_logloss: 0.100162\n",
      "[584]\tvalid_0's binary_logloss: 0.100423\n",
      "[585]\tvalid_0's binary_logloss: 0.0999481\n",
      "[586]\tvalid_0's binary_logloss: 0.100168\n",
      "[587]\tvalid_0's binary_logloss: 0.0997822\n",
      "[588]\tvalid_0's binary_logloss: 0.100039\n",
      "[589]\tvalid_0's binary_logloss: 0.100313\n",
      "[590]\tvalid_0's binary_logloss: 0.100529\n",
      "[591]\tvalid_0's binary_logloss: 0.100808\n",
      "[592]\tvalid_0's binary_logloss: 0.101069\n",
      "[593]\tvalid_0's binary_logloss: 0.100682\n",
      "[594]\tvalid_0's binary_logloss: 0.100925\n",
      "[595]\tvalid_0's binary_logloss: 0.101159\n",
      "[596]\tvalid_0's binary_logloss: 0.100763\n",
      "[597]\tvalid_0's binary_logloss: 0.101015\n",
      "[598]\tvalid_0's binary_logloss: 0.101273\n",
      "[599]\tvalid_0's binary_logloss: 0.100887\n",
      "[600]\tvalid_0's binary_logloss: 0.100428\n",
      "[601]\tvalid_0's binary_logloss: 0.100006\n",
      "[602]\tvalid_0's binary_logloss: 0.10024\n",
      "[603]\tvalid_0's binary_logloss: 0.0998482\n",
      "[604]\tvalid_0's binary_logloss: 0.100086\n",
      "[605]\tvalid_0's binary_logloss: 0.100338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[606]\tvalid_0's binary_logloss: 0.100571\n",
      "[607]\tvalid_0's binary_logloss: 0.100795\n",
      "Early stopping, best iteration is:\n",
      "[572]\tvalid_0's binary_logloss: 0.0994197\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.025,\n",
    "    'num_leaves': 51, \n",
    "    'lambda_l2': 0.01,\n",
    "    'objective':'binary',\n",
    "    'tree_learner': 'voting_parallel',\n",
    "    'bagging_freq': 10,\n",
    "    'early_stopping_rounds': 25,\n",
    "    'top_k': 35,\n",
    "    'boosting': 'gbdt', # 'gbdt' default\n",
    "}\n",
    "num_round = 900\n",
    "bst = lgb.train(params, \n",
    "                train_data, \n",
    "                num_round, \n",
    "                valid_sets=[test_data], \n",
    "#                 init_model='model.txt',\n",
    "               )\n",
    "# Save model\n",
    "bst.save_model('model.txt', num_iteration=bst.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fca633923c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_ROWS = 133223\n",
    "ROWS = TOTAL_ROWS\n",
    "test = pd.read_csv(\"./parsed_test.csv\", nrows=ROWS, header=None)\n",
    "ypred = bst.predict(test, num_iteration=bst.best_iteration)\n",
    "\n",
    "df = pd.DataFrame(ypred)\n",
    "df.to_csv('./predict.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n",
      "0.875\n",
      "0.875\n",
      "0.875\n",
      "0.875\n",
      "0.875\n",
      "0.875\n",
      "0.875\n",
      "0.875\n",
      "0.875\n",
      "0.875\n",
      "0.875\n",
      "0.875\n",
      "0.875\n",
      "0.875\n",
      "0.875\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('./output.csv', 'w', newline='') as submitcsvfile:\n",
    "    submitwriter = csv.writer(submitcsvfile)\n",
    "    submitwriter.writerow([\"sample_id\", \"malware\"])\n",
    "    with open('./predict.csv') as predictcsvfile:\n",
    "        predictreader = csv.reader(predictcsvfile)\n",
    "        with open('./parsed_indices.csv') as csvfile:\n",
    "            rowreader = csv.reader(csvfile)\n",
    "            for index, row in enumerate(rowreader):\n",
    "                if row[0] == \"0\":\n",
    "                    print(0.875)\n",
    "                    submitwriter.writerow([index, 0.875])\n",
    "                else:\n",
    "                    submitwriter.writerow([index] + predictreader.__next__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 6, 7, 20, 25, 26, 27, 28, 45, 46, 52, 53, 54, 56, 62, 65, 66, 67, 68, 73, 76, 78, 81, 82, 83, 85, 87, 88, 91, 93, 94, 95, 96, 97, 99, 101, 102, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 122, 124, 126, 128, 129, 130, 131, 132, 143, 144, 145, 146, 147, 148, 150, 151, 153, 159, 160, 161, 162, 163, 164, 165, 167, 168, 171, 173, 175, 178, 179, 181, 182, 184, 186, 187, 190, 191, 194, 196, 197, 198, 199, 201, 202, 203, 206, 211, 214, 217, 218, 219, 220, 222, 223, 226, 228, 229, 232, 234, 235, 236, 237, 239, 240, 243, 244, 245, 246, 249, 251, 253, 255, 256, 258, 259, 263, 268, 270, 271, 272, 273, 275, 276, 280, 281, 283, 286, 287, 288, 289, 290, 293, 294, 295, 296, 298, 299, 304, 305, 306, 308, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 339, 340, 341, 342, 343, 344, 345, 346, 348, 349, 350, 351, 352, 355, 356, 358, 359, 360, 361, 364, 365, 366, 367, 368, 369, 374, 375, 376, 377, 378, 379, 383, 384, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 403, 404, 405, 406, 407, 408, 409, 410, 411, 414, 415, 416, 417, 418, 419, 424, 425, 426, 427, 428, 429, 434, 435, 436, 437, 438, 439, 444, 445, 446, 447, 448, 457, 616, 618, 620, 634, 646, 654, 656, 657, 658, 660, 666, 683, 687, 694, 695, 702, 703, 707, 715, 718, 791, 796, 802, 937, 942, 943, 944, 950, 958, 962, 964, 966, 967, 968, 971, 974, 975, 977, 978, 983, 985, 986, 988, 990, 1002, 1004, 1015, 1019, 1024, 1048, 1049, 1051, 1086, 1245, 1261, 1338, 3442, 3697]\n"
     ]
    }
   ],
   "source": [
    "feature_indices = bst.feature_name()\n",
    "feature_importance = bst.feature_importance()\n",
    "\n",
    "feature_rank = []\n",
    "\n",
    "for i, index in enumerate(feature_indices):\n",
    "    importance = feature_importance[i]\n",
    "    if importance == 0:\n",
    "        continue\n",
    "    \n",
    "    feature_rank.append(int(index))\n",
    "print(feature_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_rank = [2, 3, 6, 7, 20, 25, 26, 27, 28, 45, 46, 52, 53, 54, 56, 62, 65, 66, 67, 68, 73, 76, 78, 81, 82, 83, 85, 87, 88, 91, 93, 94, 95, 96, 97, 99, 101, 102, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 122, 124, 126, 128, 129, 130, 131, 132, 143, 144, 145, 146, 147, 148, 150, 151, 153, 159, 160, 161, 162, 163, 164, 165, 167, 168, 171, 173, 175, 178, 179, 181, 182, 184, 186, 187, 190, 191, 194, 196, 197, 198, 199, 201, 202, 203, 206, 211, 214, 217, 218, 219, 220, 222, 223, 226, 228, 229, 232, 234, 235, 236, 237, 239, 240, 243, 244, 245, 246, 249, 251, 253, 255, 256, 258, 259, 263, 268, 270, 271, 272, 273, 275, 276, 280, 281, 283, 286, 287, 288, 289, 290, 293, 294, 295, 296, 298, 299, 304, 305, 306, 308, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 339, 340, 341, 342, 343, 344, 345, 346, 348, 349, 350, 351, 352, 355, 356, 358, 359, 360, 361, 364, 365, 366, 367, 368, 369, 374, 375, 376, 377, 378, 379, 383, 384, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 403, 404, 405, 406, 407, 408, 409, 410, 411, 414, 415, 416, 417, 418, 419, 424, 425, 426, 427, 428, 429, 434, 435, 436, 437, 438, 439, 444, 445, 446, 447, 448, 457, 616, 618, 620, 634, 646, 654, 656, 657, 658, 660, 666, 683, 687, 694, 695, 702, 703, 707, 715, 718, 791, 796, 802, 937, 942, 943, 944, 950, 958, 962, 964, 966, 967, 968, 971, 974, 975, 977, 978, 983, 985, 986, 988, 990, 1002, 1004, 1015, 1019, 1024, 1048, 1049, 1051, 1086, 1245, 1261, 1338, 3442, 3697]\n",
    "TOTAL_ROWS = 113636\n",
    "ROWS = 500\n",
    "\n",
    "train = pd.read_csv(\"./parsed_train.csv\", nrows=ROWS, usecols=feature_rank, header=None)\n",
    "train_label = pd.read_csv(\"./parsed_labels.csv\", nrows=ROWS, header=None)\n",
    "\n",
    "assert train.shape[0] == train_label.shape[0], \"Train and label shapes are different\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/usr/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/usr/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcuda.so.1: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libcuda.so.1: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-68b6bcd20448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Globally-importable utils.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown backend: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BACKEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_array_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 74\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/usr/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/usr/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcuda.so.1: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "own_embedding_vocab_size = 256\n",
    "\n",
    "maxlen = x_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=own_embedding_vocab_size, # 10\n",
    "                    output_dim=32, \n",
    "                    input_length=maxlen))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='elu', activity_regularizer=regularizers.l1_l2(0.0001)))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(128, activation='elu', activity_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation='elu', activity_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='elu', activity_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid', activity_regularizer=regularizers.l2(0.0001)))\n",
    "\n",
    "adam=optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['acc'])  # Compile the model\n",
    "print(model.summary())  # Summarize the model\n",
    "\n",
    "# Path to saved model weights(as hdf5)\n",
    "filepath = \"mlp_model_gbt.h5\"\n",
    "# If exists a best model, load its weights!\n",
    "if os.path.isfile(filepath):\n",
    "    print (\"Resumed model's weights from {}\".format(filepath))\n",
    "    # load weights\n",
    "#     model.load_weights(filepath)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                            monitor='val_acc',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='max')\n",
    "\n",
    "another_checkpoint = EarlyStopping(monitor='val_acc', \n",
    "                            min_delta=0.001,\n",
    "                            patience=3, \n",
    "                            verbose=1, \n",
    "                            mode='auto')\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[checkpoint, another_checkpoint])  # Fit the model\n",
    "\n",
    "model.save('mlp_model_gbt.h5')\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)  # Evaluate the model\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class Ensemble(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, regressors=None):\n",
    "        self.regressors = regressors\n",
    "        \n",
    "    def level0_to_level1(self, X):\n",
    "        self.predictions_ = []\n",
    "\n",
    "        for regressor in self.regressors:\n",
    "            self.predictions_.append(regressor.predict(X).reshape(X.shape[0],1))\n",
    "\n",
    "        return np.concatenate(self.predictions_, axis=1)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for regressor in self.regressors:\n",
    "            if regressor != nn:\n",
    "                regressor.fit(X, y)\n",
    "            else: regressor.fit(X, y, batch_size=64, epochs=1000, verbose=0) # Neural Network\n",
    "            \n",
    "        self.new_features = self.level0_to_level1(X)\n",
    "        \n",
    "        # using a large L2 regularization to prevent the ensemble from biasing toward \n",
    "        # one particular base model\n",
    "        self.combine = Ridge(alpha=10, max_iter=50000)   \n",
    "        self.combine.fit(self.new_features, y)\n",
    "\n",
    "        self.coef_ = self.combine.coef_\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.new_features = self.level0_to_level1(X)\n",
    "            \n",
    "        return self.combine.predict(self.new_features).reshape(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
