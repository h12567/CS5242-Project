{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "# Only read up to 4096 bytes, > 4096 has 100% malware rate\n",
    "MAX_SIZE = 4096\n",
    "TOTAL_ROWS =  113636\n",
    "USE_COLS = list(range(2, MAX_SIZE))\n",
    "ROWS = TOTAL_ROWS\n",
    "\n",
    "train = pd.read_csv(\"./data/train.zip\", nrows=ROWS, usecols=USE_COLS, header=None, names = list(range(0, MAX_SIZE)), error_bad_lines=False)\n",
    "train_label = pd.read_csv(\"./data/train_label.csv\", usecols=[1], nrows=ROWS)\n",
    "\n",
    "train = np.nan_to_num(train, copy=False)\n",
    "assert train.shape[0] == train_label.shape[0], \"Train and label shapes are different\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.random.rand(len(train)) < 0.8\n",
    "\n",
    "train_label = train_label.values\n",
    "\n",
    "x_train = train[mask]\n",
    "y_train = train_label[mask]\n",
    "x_test = train[~mask]\n",
    "y_test = train_label[~mask]\n",
    "\n",
    "train = None\n",
    "train_label = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/.local/share/virtualenvs/CS5242-xoh8m7DM/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4094, 32)          8192      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4094, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 131008)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33538304  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 33,591,681\n",
      "Trainable params: 33,590,721\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/21\n",
      "91067/91067 [==============================] - 1130s 12ms/step - loss: 1.5636 - acc: 0.8843\n",
      "Epoch 2/21\n",
      "91067/91067 [==============================] - 1143s 13ms/step - loss: 0.5365 - acc: 0.9114\n",
      "Epoch 3/21\n",
      "91067/91067 [==============================] - 1206s 13ms/step - loss: 0.6943 - acc: 0.9189\n",
      "Epoch 4/21\n",
      "91067/91067 [==============================] - 1213s 13ms/step - loss: 0.5967 - acc: 0.9235\n",
      "Epoch 5/21\n",
      "91067/91067 [==============================] - 1183s 13ms/step - loss: 0.4420 - acc: 0.9261\n",
      "Epoch 6/21\n",
      "91067/91067 [==============================] - 1202s 13ms/step - loss: 0.5323 - acc: 0.9262\n",
      "Epoch 7/21\n",
      "91067/91067 [==============================] - 1193s 13ms/step - loss: 0.4586 - acc: 0.9239\n",
      "Epoch 8/21\n",
      "91067/91067 [==============================] - 1192s 13ms/step - loss: 0.5611 - acc: 0.9239\n",
      "Epoch 9/21\n",
      "91067/91067 [==============================] - 1143s 13ms/step - loss: 0.4506 - acc: 0.9260\n",
      "Epoch 10/21\n",
      "91067/91067 [==============================] - 1133s 12ms/step - loss: 0.6488 - acc: 0.9258\n",
      "Epoch 11/21\n",
      "91067/91067 [==============================] - 1133s 12ms/step - loss: 0.4700 - acc: 0.9260\n",
      "Epoch 12/21\n",
      "91067/91067 [==============================] - 1133s 12ms/step - loss: 0.5227 - acc: 0.9249\n",
      "Epoch 13/21\n",
      "91067/91067 [==============================] - 1133s 12ms/step - loss: 0.4706 - acc: 0.9262\n",
      "Epoch 14/21\n",
      "91067/91067 [==============================] - 1135s 12ms/step - loss: 0.5258 - acc: 0.9258\n",
      "Epoch 15/21\n",
      "91067/91067 [==============================] - 1136s 12ms/step - loss: 0.5392 - acc: 0.9265\n",
      "Epoch 16/21\n",
      "91067/91067 [==============================] - 1135s 12ms/step - loss: 0.5232 - acc: 0.9235\n",
      "Epoch 17/21\n",
      "91067/91067 [==============================] - 1133s 12ms/step - loss: 0.5606 - acc: 0.9259\n",
      "Epoch 18/21\n",
      "91067/91067 [==============================] - 1138s 12ms/step - loss: 0.6564 - acc: 0.9240\n",
      "Epoch 19/21\n",
      "91067/91067 [==============================] - 1138s 12ms/step - loss: 0.5396 - acc: 0.9261\n",
      "Epoch 20/21\n",
      "91067/91067 [==============================] - 1135s 12ms/step - loss: 0.5468 - acc: 0.9254\n",
      "Epoch 21/21\n",
      "91067/91067 [==============================] - 1134s 12ms/step - loss: 0.6858 - acc: 0.9237\n",
      "Accuracy: 0.944\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "own_embedding_vocab_size = 256\n",
    "\n",
    "maxlen = 4094\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=own_embedding_vocab_size, # 10\n",
    "                    output_dim=32, \n",
    "                    input_length=maxlen))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='elu', activity_regularizer=regularizers.l1_l2(0.0001)))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(128, activation='elu', activity_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation='elu', activity_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='elu', activity_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid', activity_regularizer=regularizers.l2(0.0001)))\n",
    "\n",
    "adam=optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['acc'])  # Compile the model\n",
    "print(model.summary())  # Summarize the model\n",
    "model.fit(x_train, y_train, epochs=21, verbose=1)  # Fit the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)  # Evaluate the model\n",
    "model.save('mlp_model.h5')\n",
    "print('Accuracy: %0.3f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`steps=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps` or use the `keras.utils.Sequence` class.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-713a62598b14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# test = pd.read_csv(\"./data/test.csv\", nrows=ROWS, usecols=USE_COLS, header=None, names = list(range(0, MAX_SIZE)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# test = np.nan_to_num(test, copy=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_arrays_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sample_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'malware'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'malware'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CS5242-xoh8m7DM/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CS5242-xoh8m7DM/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1351\u001b[0m                                             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m                                             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1353\u001b[0;31m                                             verbose=verbose)\n\u001b[0m\u001b[1;32m   1354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CS5242-xoh8m7DM/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CS5242-xoh8m7DM/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   2463\u001b[0m                 \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2465\u001b[0;31m                 raise ValueError('`steps=None` is only valid for a generator'\n\u001b[0m\u001b[1;32m   2466\u001b[0m                                  \u001b[0;34m' based on the `keras.utils.Sequence` class.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m                                  \u001b[0;34m' Please specify `steps` or use the'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `steps=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps` or use the `keras.utils.Sequence` class."
     ]
    }
   ],
   "source": [
    "TOTAL_ROWS = 133223\n",
    "ROWS = TOTAL_ROWS\n",
    "\n",
    "def generate_arrays_from_file(path):\n",
    "    while True:\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                yield np.nan_to_num(line[2:MAX_SIZE], copy=False)\n",
    "# test = pd.read_csv(\"./data/test.csv\", nrows=ROWS, usecols=USE_COLS, header=None, names = list(range(0, MAX_SIZE)))\n",
    "# test = np.nan_to_num(test, copy=False)\n",
    "ypred = model.predict_generator(generate_arrays_from_file(\"./data/test.csv\"), workers=1, use_multiprocessing=False, verbose=1)\n",
    "\n",
    "df = pd.DataFrame({'sample_id': range(1, len(test) + 1), 'malware': ypred.flatten()}, columns=['sample_id', 'malware'])\n",
    "df.to_csv('./data/predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
