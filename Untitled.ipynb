{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import csv\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "def gen_rows(stream, max_length=None):\n",
    "    rows = csv.reader(stream)\n",
    "    if max_length is None:\n",
    "        rows = list(rows)\n",
    "        max_length = max(len(row) for row in rows)\n",
    "    for row in rows:\n",
    "        yield row + [None] * (max_length - len(row))\n",
    "\n",
    "with open('./sample_data.csv') as f:\n",
    "    x_train = pd.DataFrame.from_records(list(gen_rows(f)))\n",
    "\n",
    "y_train = pd.read_csv('./sample_label.csv')\n",
    "# x_train = pd.read_csv('./sample_data.csv', names=list(range(8192)))\n",
    "\n",
    "x_train = x_train.iloc[:].values\n",
    "x_train = np.array(x_train, dtype=np.float)\n",
    "x_train[np.isnan(x_train)] = 0\n",
    "# x_train = sc.fit_transform(x_train)\n",
    "y_train = y_train.iloc[:].values\n",
    "y_train = map(lambda x: x[1], y_train)\n",
    "y_train = np.fromiter(y_train, dtype = np.int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num must be 1 <= num <= 4, not 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-56b0c4246ab8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m900\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#         a.set_title(y_train[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lth08091998/anaconda3/envs/tensorflow/lib/python3.4/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1068\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lth08091998/anaconda3/envs/tensorflow/lib/python3.4/site-packages/matplotlib/axes/_subplots.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m                     raise ValueError(\n\u001b[1;32m     63\u001b[0m                         \"num must be 1 <= num <= {maxn}, not {num}\".format(\n\u001b[0;32m---> 64\u001b[0;31m                             maxn=rows*cols, num=num))\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subplotspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;31m# num - 1 for converting from MATLAB to python indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: num must be 1 <= num <= 4, not 5"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd4AAAHVCAYAAABfWZoAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFwCAhCi8AAAk9P8ALb78L263P5MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc0c93bc898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "n = 1\n",
    "\n",
    "for i in range(100):\n",
    "    if(y_train[i] == 0):\n",
    "        im = x_train[i, 0: 900].astype(int)\n",
    "        im = im.reshape(30, 30)\n",
    "        a = fig.add_subplot(2, 2, n)\n",
    "        n += 1\n",
    "#         a.set_title(y_train[i])\n",
    "        plt.gray()\n",
    "        plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num must be 1 <= num <= 1, not 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-fe3b88a53b9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lth08091998/anaconda3/envs/tensorflow/lib/python3.4/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1068\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lth08091998/anaconda3/envs/tensorflow/lib/python3.4/site-packages/matplotlib/axes/_subplots.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m                     raise ValueError(\n\u001b[1;32m     63\u001b[0m                         \"num must be 1 <= num <= {maxn}, not {num}\".format(\n\u001b[0;32m---> 64\u001b[0;31m                             maxn=rows*cols, num=num))\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subplotspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;31m# num - 1 for converting from MATLAB to python indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: num must be 1 <= num <= 1, not 2"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdgAAAHVCAYAAABSR+pHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa77c076d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(8, 8))\n",
    "n = 1\n",
    "\n",
    "for i in range(100):\n",
    "    if(y_train[i] == 1):\n",
    "        im = x_train[i].astype(int)\n",
    "        im = im.reshape(64, 64)\n",
    "        a = fig.add_subplot(1, 1, n)\n",
    "        n += 1\n",
    "        plt.gray()\n",
    "        plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_reshaped_train = np.zeros((x_train.shape[0], 30, 30, 1))\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    x_reshaped_train[i] = x_train[i, 0: 900].astype(int).reshape(30, 30, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 30, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_reshaped_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_reshaped_train = np.zeros((y_train.shape[0], 2), dtype=int)\n",
    "for i in range(y_train.shape[0]):\n",
    "    if(y_train[i] == 0):\n",
    "        y_reshaped_train[i] = [1, 0]\n",
    "    else:\n",
    "        y_reshaped_train[i] = [0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.638\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(x_train.shape[0]):\n",
    "    if(y_train[i] == 1):\n",
    "        cnt += 1\n",
    "        \n",
    "print(cnt / 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 5.6900 - acc: 0.6200\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 8s 15ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 8s 16ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 8s 16ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 8s 16ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 5.8348 - acc: 0.6380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc0a8216898>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import *\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(1, 1), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=(30, 30, 1)))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_reshaped_train, y_reshaped_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1)\n",
    "#           validation_data=(x_test, y_test),\n",
    "#           callbacks=[history])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[137  44]\n",
      " [ 27 292]]\n",
      "0.858\n"
     ]
    }
   ],
   "source": [
    "d_train = lgb.Dataset(x_train, label=y_train)\n",
    "\n",
    "# print(d_train)\n",
    "\n",
    "params = {}\n",
    "params['learning_rate'] = 0.003\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'binary'\n",
    "params['metric'] = 'binary_logloss'\n",
    "params['sub_feature'] = 0.5\n",
    "params['num_leaves'] = 100\n",
    "params['min_data'] = 50\n",
    "params['max_depth'] = 100\n",
    "\n",
    "\n",
    "clf = lgb.train(params, d_train, 10)\n",
    "\n",
    "y_pred=clf.predict(x_train)\n",
    "#convert into binary values\n",
    "for i in range(x_train.shape[0]):\n",
    "    if y_pred[i]>=.5:       # setting threshold to .5\n",
    "       y_pred[i]=1\n",
    "    else:  \n",
    "       y_pred[i]=0\n",
    "\n",
    "y_pred = y_pred.astype(np.int)\n",
    "\n",
    "# print(y_pred)\n",
    "# print(y_train)\n",
    "\n",
    "# # result = 0\n",
    "# # for i in range(y_pred.shape[0]):\n",
    "# # \tif(y_pred[i] != y_train[i]):\n",
    "# # \t\tresult += 1\n",
    "\n",
    "# # print(\"ACCURACY \")\n",
    "# # print((y_pred.shape[0] - result) / y_pred.shape[0])\n",
    "\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "print(cm)\n",
    "accuracy=accuracy_score(y_pred,y_train)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
