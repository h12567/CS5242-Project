{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "# Only read up to 4096 bytes, > 4096 has 100% malware rate\n",
    "MAX_SIZE = 4096\n",
    "TOTAL_ROWS =  113636\n",
    "TOTAL_ROWS = 500\n",
    "USE_COLS = list(range(2, MAX_SIZE))\n",
    "ROWS = TOTAL_ROWS\n",
    "\n",
    "train = pd.read_csv(\"./sample_data.csv\", nrows=ROWS, usecols=USE_COLS, header=None, names = list(range(0, MAX_SIZE)), error_bad_lines=False)\n",
    "train_label = pd.read_csv(\"./sample_label.csv\", usecols=[1], nrows=ROWS)\n",
    "\n",
    "train = train.fillna(0, downcast='infer')\n",
    "assert train.shape[0] == train_label.shape[0], \"Train and label shapes are different\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "mask = np.random.rand(len(train)) < 0.8\n",
    "\n",
    "train_data = train.values\n",
    "train_labels = train_label.values\n",
    "\n",
    "x_train = train_data[mask]\n",
    "y_train = train_labels[mask]\n",
    "x_test = train_data[~mask]\n",
    "y_test = train_labels[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "\n",
    "    def __init__(self, init='glorot_uniform', kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None,  **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get(init)\n",
    "        self.kernel_initializer = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight((input_shape[-1], 1),\n",
    "                                 initializer=self.kernel_initializer,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.kernel_regularizer,\n",
    "                                 constraint=self.kernel_constraint)\n",
    "        self.b = self.add_weight((input_shape[1],),\n",
    "                                 initializer='zero',\n",
    "                                 name='{}_b'.format(self.name),\n",
    "                                 regularizer=self.bias_regularizer,\n",
    "                                 constraint=self.bias_constraint)\n",
    "\n",
    "        self.u = self.add_weight((input_shape[1],),\n",
    "                                 initializer=self.kernel_initializer,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.kernel_regularizer,\n",
    "                                 constraint=self.kernel_constraint)\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, mask):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        multData =  K.dot(x, self.kernel) \n",
    "        multData = K.squeeze(multData, -1)\n",
    "        multData = multData + self.b \n",
    "\n",
    "        multData = K.tanh(multData) \n",
    "\n",
    "        multData = multData * self.u \n",
    "        multData = K.exp(multData) \n",
    "\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx()) \n",
    "            multData = mask*multData \n",
    "\n",
    "        multData /= K.cast(K.sum(multData, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        multData = K.expand_dims(multData)\n",
    "        weighted_input = x * multData\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4094, 32)          8192      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4094, 32)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 4094, 64)          24832     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4094, 32)          12416     \n",
      "_________________________________________________________________\n",
      "attention_1 (Attention)      (None, 32)                8220      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 53,821\n",
      "Trainable params: 53,757\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "414/414 [==============================] - 47s 114ms/step - loss: 0.6834 - acc: 0.6329\n",
      "Epoch 2/50\n",
      "320/414 [======================>.......] - ETA: 9s - loss: 0.5376 - acc: 0.7125 "
     ]
    }
   ],
   "source": [
    "train_labels = train_label.values\n",
    "\n",
    "own_embedding_vocab_size = 256\n",
    "\n",
    "maxlen = 4094\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=own_embedding_vocab_size, # 10\n",
    "                    output_dim=32, \n",
    "                    input_length=maxlen))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "\n",
    "model.add(Attention())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "adam=optimizers.Adam(lr=0.01)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['acc'])  # Compile the model\n",
    "print(model.summary())  # Summarize the model\n",
    "model.fit(x_train, y_train, epochs=50, verbose=1, batch_size=64)  # Fit the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)  # Evaluate the model\n",
    "model.save('mlp_model.h5')\n",
    "print('Accuracy: %0.3f' % accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
